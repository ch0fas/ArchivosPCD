{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introducción 📖\n",
    "\n",
    "En la clase anterior vimos la motivación y los principios de **MLOps**.\n",
    "En esta clase vamos a profundizar en cómo pensar los proyectos de machine learning desde una perspectiva de **software engineering**.\n",
    "\n",
    "El desarrollo de ML no ocurre en el vacío:\n",
    "- Inicia con **datos**, que deben ser gestionados y versionados.\n",
    "- Continúa con **modelos**, que no solo se entrenan, sino que deben ser empaquetados, validados y preparados para producción.\n",
    "- Y culmina en **código**, que integra el modelo con aplicaciones reales a través de pipelines y servicios desplegables.\n",
    "\n",
    "Este enfoque nos permite entender que los sistemas de ML no son solo algoritmos aislados, sino **arquitecturas completas** que involucran infraestructura, patrones de despliegue y consideraciones de operación continua.\n",
    "\n",
    "👉 El objetivo de esta sesión es **reconocer las piezas clave de un sistema ML como software**, sus patrones de diseño y las estrategias más comunes para integrarlo en producción."
   ],
   "id": "1203e85a0629b691"
  },
  {
   "cell_type": "markdown",
   "id": "253ad27638b24b3a",
   "metadata": {},
   "source": [
    "# 1. 🎯 Tres Niveles del Software de ML\n",
    "\n",
    "https://ml-ops.org/content/three-levels-of-ml-software\n",
    "\n",
    "- 📈 La adopción de ML/IA está creciendo rápidamente en nuevas aplicaciones e industrias.\n",
    "- 🎯 El objetivo de un proyecto de machine learning es construir un modelo estadístico utilizando datos recopilados y aplicando algoritmos de machine learning.\n",
    "- 🚧 Construir proyectos de software exitosos basados en ML sigue siendo difícil porque cada software de ML debe gestionar tres activos principales:\n",
    "  - 📊 **Datos**\n",
    "  - 🧠 **Modelo**\n",
    "  - 💻 **Código**\n",
    "- 🛠️ La gestión de la operacionalización de modelos de machine learning - **MLOps**, como una extensión de **DevOps**, establece prácticas y procesos efectivos en torno a:\n",
    "  - El diseño\n",
    "  - La construcción\n",
    "  - El despliegue de modelos de ML en producción.\n",
    "- 🧑‍🔧 Las metodologías técnicas esenciales involucradas en el desarrollo de software basado en machine learning son:\n",
    "  - **Data Engineering**\n",
    "  - **ML Model Engineering**\n",
    "  - **Software Release Engineering**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f2f3eced3c4bf",
   "metadata": {},
   "source": [
    "## 1.1 📊 Datos: Pipelines de Data Engineering\n",
    "\n",
    "- 🌐 El componente fundamental de cualquier flujo de trabajo de machine learning es el **dato**.\n",
    "- 📉 La calidad y el rendimiento del modelo de ML dependen en gran medida de la calidad de los datos.\n",
    "    - **\"Garbage In, Garbage Out\"**: El modelo de ML es tan bueno como lo sean los datos.\n",
    "    - Los datos utilizados para entrenar el modelo influyen en el rendimiento del sistema en producción.\n",
    "    - La cantidad y calidad del conjunto de datos son específicas del problema y se descubren empíricamente.\n",
    "- ⏳ **La ingeniería de datos** es una de las etapas más consumidoras de tiempo en un proyecto de machine learning:\n",
    "    - Se puede gastar la mayor parte del tiempo construyendo conjuntos de datos, limpiando y transformando los datos.\n",
    "- 🔄 El pipeline de ingeniería de datos incluye una **secuencia de operaciones** sobre los datos disponibles:\n",
    "    - El objetivo final es crear conjuntos de datos de entrenamiento y prueba para los algoritmos de ML.\n",
    "    - Las etapas incluyen Ingesta de Datos, Exploración y Validación, Limpieza (Data Wrangling) y División de Datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a3eadd1f6432b",
   "metadata": {},
   "source": [
    "### 1.1.1 🚀 Data Ingestion\n",
    "- 🌐 Recolección de datos utilizando diversos sistemas, frameworks y formatos:\n",
    "    - Bases de datos internas/externas, data marts, OLAP cubes, almacenes de datos, OLTP systems, Spark, HDFS, etc.\n",
    "    - También puede incluir la generación de datos sintéticos o el enriquecimiento de datos.\n",
    "- 📋 Las mejores prácticas incluyen:\n",
    "    - **Identificación de Fuentes de Datos**: Encontrar los datos y documentar su origen.\n",
    "    - **Estimación de Espacio**: Calcular cuánto espacio de almacenamiento ocuparán.\n",
    "    - **Ubicación de Espacio**: Crear un área de trabajo con suficiente espacio de almacenamiento.\n",
    "    - **Obtención de Datos**: Convertir los datos a un formato manipulable sin modificarlos.\n",
    "    - **Copia de Seguridad**: Trabajar siempre con una copia de los datos originales.\n",
    "    - **Cumplimiento de Privacidad**: Proteger información sensible para cumplir con normativas como GDPR.\n",
    "    - **Catálogo de Metadatos**: Documentar información básica como tamaño, formato y control de acceso.\n",
    "    - **Conjunto de Prueba**: Separar un conjunto de prueba y no usarlo durante el entrenamiento.\n",
    "\n",
    "### 1.1.2 🔍 Exploración y Validación\n",
    "- 📊 Implica el perfilado de datos para obtener información sobre su contenido y estructura:\n",
    "    - El resultado es un conjunto de metadatos como valor máximo, mínimo y promedio.\n",
    "- ✅ Validación de datos mediante funciones de detección de errores definidos por el usuario:\n",
    "    - Evaluación de la calidad ejecutando rutinas de validación de datos.\n",
    "    - Ejemplo: ¿El código postal es correcto? ¿Faltan valores en los atributos importantes?\n",
    "- 🛠️ Mejores prácticas incluyen:\n",
    "    - **Uso de herramientas RAD (Rapid Application Development)**: Usar notebooks como Jupyter para registrar la exploración de datos.\n",
    "    - **Perfilado de Atributos**: Documentar metadatos como el nombre, tipo de dato y estadísticas clave.\n",
    "    - **Identificación de Etiquetas**: Identificar el atributo objetivo para tareas supervisadas.\n",
    "    - **Visualización de Datos**: Crear gráficos para representar la distribución de valores.\n",
    "    - **Correlación de Atributos**: Analizar correlaciones entre los atributos.\n",
    "\n",
    "### 1.1.3  🛠️ Limpieza de Datos (Data Wrangling)\n",
    "- 🔄 Preparación de los datos mediante la reestructuración o ajuste de atributos:\n",
    "    - Reutilizar scripts y funciones para transformaciones futuras.\n",
    "- 🧹 Operaciones comunes incluyen:\n",
    "  - **Transformaciones**: Aplicar transformaciones útiles.\n",
    "    - **Corrección de Valores Atípicos**: Eliminar o corregir outliers (opcional).\n",
    "    - **Manejo de Valores Faltantes**: Rellenar valores o eliminar filas/columnas.\n",
    "    - **Eliminación de Datos Irrelevantes**: Eliminar atributos que no aporten información.\n",
    "    - **Reestructuración de Datos**: Reordenar, crear nuevos campos, combinar campos, y más.\n",
    "\n",
    "### 1.1.4 🔀 División de Datos\n",
    "- 📊 Separar los datos en conjuntos de entrenamiento (80%), validación y prueba:\n",
    "    - Utilizados durante las etapas principales de ML para construir y evaluar el modelo.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375fc0b578f3168",
   "metadata": {},
   "source": [
    "## 1.2 🛠️ Modelo: Pipelines de Machine Learning\n",
    "- 🔑 El núcleo del flujo de trabajo de ML es la fase de escritura y ejecución de algoritmos de machine learning para obtener un modelo ML.\n",
    "- 🧑‍💻 El pipeline de model engineering es utilizado por un equipo de ciencia de datos e incluye varias operaciones que llevan a un modelo final:\n",
    "    - **Model Training**\n",
    "    - **Model Evaluation**\n",
    "    - **Model Testing**\n",
    "    - **Model Packaging**\n",
    "\n",
    "### 1.2.1 📚 Entrenamiento del Modelo\n",
    "- 🎯 Proceso de aplicar el algoritmo de machine learning en los datos de entrenamiento para entrenar un modelo ML.\n",
    "- 🔧 Incluye la ingeniería de características y el ajuste de hiperparámetros:\n",
    "\n",
    "    - **Ingeniería de Características**:\n",
    "        - 🔹 Discretizar características continuas.\n",
    "        - 🔹 Descomponer características (ej. categóricas, fecha/hora, etc.).\n",
    "        - 🔹 Agregar transformaciones de características (ej. log(x), sqrt(x), x², etc.).\n",
    "        - 🔹 Transformar características en nuevas características prometedoras.\n",
    "        - 🔹 Escalado de características: Estandarizar o normalizar características.\n",
    "\n",
    "    - **Ingeniería del Modelo**:\n",
    "\n",
    "        - Cada especificación de modelo ML (código) debe pasar por revisión de código y ser versionada.\n",
    "        - Entrenar múltiples modelos de ML de diferentes categorías (ej. regresión lineal, k-means, SVM, etc.).\n",
    "        - Medir y comparar su rendimiento con validación cruzada.\n",
    "        - Análisis de errores: analizar los tipos de errores cometidos por los modelos ML.\n",
    "        - Selección e ingeniería de características adicionales.\n",
    "        - Identificar de tres a cinco modelos más prometedores.\n",
    "        - Ajuste de hiperparámetros utilizando validación cruzada.\n",
    "        - Considerar métodos de ensamble como voto mayoritario, bagging, boosting, o stacking.\n",
    "\n",
    "\n",
    "### 1.2.2 ✔️ Model Evaluation\n",
    "- ✅ Validar el modelo entrenado para asegurar que cumple con los objetivos de negocio originales antes de implementarlo en producción.\n",
    "\n",
    "### 1.2.3 🧪 Model Testing\n",
    "- 📈 Una vez que el modelo ML final está entrenado, su rendimiento debe medirse usando un conjunto de datos de prueba reservado para estimar el error de generalización mediante la “Prueba de Aceptación del Modelo”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd64086f895e796",
   "metadata": {},
   "source": [
    "### 1.2.4 📦 Model Packaging\n",
    "\n",
    "- 🗂️ Proceso de exportar el modelo de ML final en un formato específico (ej. PMML, PFA, ONNX, pickle, bin, etc) que describe el modelo para su consumo por aplicaciones de negocio.\n",
    "\n",
    "#### 🔄 Diferentes Formas de Flujos de Trabajo de ML\n",
    "Operar un modelo de ML puede suponer varios estilos arquitectónicos. A continuación, discutimos cuatro patrones arquitectónicos que se clasifican a lo largo de dos dimensiones:\n",
    "\n",
    "1. **Entrenamiento de Modelos de ML**\n",
    "2. **Predicción o Inferencia de Modelos de ML**\n",
    "\n",
    "Hay dos formas en las que realizamos el entrenamiento de modelos de ML:\n",
    "\n",
    "- **Aprendizaje Offline** (también conocido como aprendizaje por lotes (batch) o estático): El modelo se entrena en un conjunto de datos ya recolectados. Después de ser desplegado en el entorno de producción, el modelo de ML permanece constante hasta que se vuelve a entrenar, porque el modelo verá muchos datos en tiempo real y se volverá obsoleto. Este fenómeno se llama ‘decadencia del modelo’ y debe ser monitoreado cuidadosamente.\n",
    "\n",
    "- **Aprendizaje Online** (también conocido como aprendizaje dinámico): El modelo se vuelve a entrenar regularmente a medida que llegan nuevos datos, por ejemplo, a medida que se generan flujos de datos. Este es el caso habitual de los sistemas de ML que utilizan datos de series temporales, como datos de sensores o de trading de acciones, para acomodar los efectos temporales en el modelo de ML.\n",
    "\n",
    "La segunda dimensión es **Predicción o Inferencia de Modelos de ML**, que denota la mecánica mediante la cual el modelo de ML hace predicciones. Aquí también distinguimos dos modos:\n",
    "\n",
    "- **Predicciones por Lotes**: El modelo de ML desplegado realiza un conjunto de predicciones basadas en datos de entrada históricos. Esto suele ser suficiente para datos que no son dependientes del tiempo, o cuando no es crítico obtener predicciones en tiempo real como salida.\n",
    "\n",
    "- **Predicciones en Tiempo Real** (también conocidas como predicciones bajo demanda): Las predicciones se generan en tiempo real utilizando los datos de entrada que están disponibles en el momento de la solicitud.\n",
    "\n",
    "Después de identificar estas dos dimensiones, podemos clasificar la operacionalización de modelos de machine learning en cuatro patrones arquitectónicos de ML:\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/model-serving-pattern.png\" width=\"880\" height=\"50\">\n",
    "\n",
    "A continuación, veamos una descripción de los patrones arquitectónicos del modelo, como **Forecast**, **Web Service/API**, **Online Learning**, y **AutoML**.\n",
    "\n",
    "##### 🔮 Forecast/Batch Prediction\n",
    "- Este tipo de flujo de trabajo de machine learning es ampliamente utilizado en la investigación académica o en la educación de ciencia de datos (por ejemplo, Kaggle o DataCamp).\n",
    "- Esta forma se utiliza para experimentar con algoritmos de ML y datos, ya que es la manera más sencilla de crear un sistema de machine learning. Por lo general, tomamos un conjunto de datos disponible, entrenamos el modelo de ML, luego ejecutamos este modelo en otro conjunto de datos (principalmente históricos), y el modelo de ML realiza predicciones.\n",
    "\n",
    "Ejemplos:\n",
    "1. **Análisis de ventas mensuales**:\n",
    "   - Una empresa de comercio electrónico realiza predicciones mensuales sobre las ventas de sus productos. Cada mes, recopilan los datos de ventas históricos y utilizan un modelo de machine learning para predecir las ventas del próximo mes. Esta predicción se ejecuta de una sola vez en todos los datos históricos y se utiliza para la planificación y la toma de decisiones.\n",
    "\n",
    "2. **Evaluación de riesgo crediticio**:\n",
    "   - Un banco puede usar un modelo para evaluar el riesgo de crédito de todos sus solicitantes de préstamos en un batch. Cada semana, el banco recopila todas las solicitudes de préstamos y ejecuta el modelo de predicción en todos los datos recopilados para decidir si aprobar o rechazar cada solicitud.\n",
    "\n",
    "\n",
    "##### 🌐 Web Service/API\n",
    "- La arquitectura de despliegue de modelos de ML más comúnmente descrita es un web service (microservicio), el cuál toma datos de entrada y devuelve una predicción para los puntos de datos de entrada.\n",
    "- El modelo se entrena offline con datos históricos, pero utiliza datos en tiempo real para hacer predicciones.\n",
    "- La diferencia con un forecast es que el modelo de ML funciona casi en tiempo real y maneja un solo registro a la vez en lugar de procesar todos los datos a la vez.\n",
    "- El web service utiliza datos en tiempo real para hacer predicciones, pero el modelo permanece constante hasta que se vuelve a entrenar y se despliega nuevamente en el sistema de producción.\n",
    "\n",
    "Ejemplos:\n",
    "1. **Detección de fraudes en transacciones**:\n",
    "   - Un sistema de pagos en línea implementa un modelo de machine learning que evalúa cada transacción en tiempo real. Si un usuario realiza una compra, el sistema analiza los datos de la transacción en ese momento para detectar patrones de fraude. Si se identifica una actividad sospechosa, la transacción se bloquea o se revisa adicionalmente.\n",
    "\n",
    "2. **Estimación del tiempo de recorrido en taxis**\n",
    "   - Uber/Didi/Lyft utiliza un modelo de machine learning que estima el tiempo de recorrido en tiempo real. A medida que los pasajeros solicitan viajes, el sistema recopila datos como la ubicación del pasajero y del conductor, así como las condiciones del tráfico.\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/model-serving-as-microservice.png\" width=\"880\" height=\"50\">\n",
    "\n",
    "##### 🚀 Online Learning\n",
    "- La forma más dinámica de incorporar machine learning en un sistema de producción es implementar el aprendizaje online, que también se conoce como analítica de streaming en tiempo real.\n",
    "- Cabe mencionar que el término aprendizaje online puede ser confuso, ya que el aprendizaje o el entrenamiento del modelo de ML generalmente no se realizan en el sistema en vivo.\n",
    "- Deberíamos llamarlo `incremental learning`; sin embargo, el término Online Learning ya está establecido dentro de la comunidad de ML.\n",
    "- El algoritmo de aprendizaje de ML recibe continuamente un flujo de datos, ya sea como puntos de datos individuales o en pequeños grupos llamados mini-batches.\n",
    "- El sistema aprende sobre nuevos datos al instante a medida que llegan, por lo que el modelo de ML se vuelve a entrenar incrementalmente con nuevos datos.\n",
    "- Este modelo que se vuelve a entrenar continuamente está instantáneamente disponible como un servicio web.\n",
    "- Por lo general, los datos de entrada son un flujo de eventos, y el modelo de ML toma los datos a medida que ingresan al sistema, proporciona predicciones y se vuelve a entrenar con estos nuevos datos.\n",
    "- El modelo típicamente se ejecuta como un servicio en un clúster de Kubernetes o similar.\n",
    "\n",
    "Un gran desafío con el sistema de aprendizaje online en producción es que si datos erróneos ingresan al sistema, el modelo de ML, así como el rendimiento de todo el sistema, disminuirán cada vez más.\n",
    "\n",
    "Ejemplos:\n",
    "1. **Recomendaciones en tiempo real**:\n",
    "   - Una plataforma de streaming de música utiliza un modelo de machine learning para recomendar canciones a los usuarios. A medida que un usuario escucha música, el sistema genera recomendaciones en tiempo real basadas en sus preferencias y el comportamiento de escucha actual. Esto permite que el usuario reciba sugerencias personalizadas al instante.\n",
    "\n",
    "2. **Optimización de precios en e-commerce**:\n",
    "   - Un sitio de comercio electrónico utiliza un modelo de machine learning para ajustar los precios de los productos en tiempo real. A medida que los clientes navegan y realizan compras, el sistema analiza datos como la demanda, el comportamiento de los usuarios, y la competencia. Esto permite modificar los precios instantáneamente para maximizar las ventas y aumentar los ingresos, ofreciendo descuentos o ajustando precios según la oferta y la demanda.\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/online-learning.png\" width=\"880\" height=\"50\">\n",
    "\n",
    "##### ⚙️ AutoML\n",
    "- Una versión aún más sofisticada del aprendizaje online es el aprendizaje automático automatizado o AutoML.\n",
    "- AutoML está recibiendo mucha atención y se considera el próximo avance para ML en empresas.\n",
    "- AutoML promete entrenar modelos de ML con un esfuerzo mínimo y sin la necesidad de experiencia en machine learning.\n",
    "- El usuario necesita proporcionar datos, y el sistema AutoML selecciona automáticamente un algoritmo de ML, como una arquitectura de red neuronal, y configura el algoritmo seleccionado.\n",
    "- En lugar de actualizar el modelo, ejecutamos toda un pipeline de entrenamiento de modelos de ML en producción que resulta en nuevos modelos al instante.\n",
    "- AutoML suele ser proporcionado por grandes proveedores de la nube, como Google o MS Azure. Sin embargo, los modelos construidos con AutoML deben alcanzar el nivel de precisión requerido para el éxito en el mundo real.\n",
    "\n",
    "Ejemplos de Herramientas de AutoML\n",
    "\n",
    "1. [Google Cloud AutoML](https://cloud.google.com/automl)\n",
    "   - Permite a los usuarios entrenar modelos personalizados de aprendizaje automático para tareas específicas, como clasificación de imágenes, análisis de texto y traducción automática, sin necesidad de tener experiencia en ML.\n",
    "\n",
    "2. [Microsoft Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/)\n",
    "   - Ofrece un servicio de AutoML que permite a los usuarios seleccionar conjuntos de datos y definir el problema (como clasificación o regresión), y el sistema seleccionará automáticamente el mejor modelo y optimizará los hiperparámetros.\n",
    "\n",
    "3. [H2O.ai](https://www.h2o.ai/)\n",
    "   - H2O Driverless AI es una plataforma que automatiza el proceso de creación de modelos de machine learning, incluyendo la selección de características, la selección del modelo y la optimización de hiperparámetros.\n",
    "\n",
    "4. [DataRobot](https://www.datarobot.com/)\n",
    "   - Permite a los usuarios cargar datos y construir modelos predictivos automáticamente. Ofrece una interfaz fácil de usar para explorar los modelos generados y sus métricas de rendimiento.\n",
    "\n",
    "5. [Auto-sklearn](https://automl.github.io/auto-sklearn/master/)\n",
    "   - Una biblioteca de Python que utiliza Scikit-learn para automatizar el proceso de selección y optimización de modelos de machine learning.\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f3b14ff2ea3d5f",
   "metadata": {},
   "source": [
    "## 1.3 🚀 Código: Deployment Pipelines\n",
    "\n",
    "La etapa final de entrega de un proyecto de ML incluye los siguientes tres pasos:\n",
    "\n",
    "1. **Model Serving**\n",
    "2. **Model Performance Monitoring**\n",
    "3. **Model Performance Logging**\n",
    "\n",
    "### 1.3.1 📊 Model Serving Patterns\n",
    "\n",
    "- Tres componentes deben ser considerados al servir un modelo de ML en un entorno de producción.\n",
    "- La inferencia es el proceso de obtener datos que serán ingeridos por un modelo para calcular predicciones.\n",
    "- Este proceso requiere un `modelo`, un `intérprete` para la ejecución y `datos de entrada`.\n",
    "- Desplegar un sistema de ML en un entorno de producción incluye dos aspectos: primero, desplegar el pipeline para el re-entrenamiento automatizado y la implementación del modelo de ML; segundo, proporcionar la API para la predicción en datos no vistos.\n",
    "- El **model serving** es una forma de integrar el modelo de ML en un sistema de software.\n",
    "- Tenemos tres patrones para poner el modelo de ML en producción: **Model-as-Service**, **Model-as-Dependency** y **Precompute**.\n",
    "\n",
    "#### 1. Model-as-Service\n",
    "- **Model-as-Service** es un patrón común para contener un modelo de ML como un servicio independiente. Podemos contener el modelo de ML y el intérprete dentro de un servicio web dedicado que las aplicaciones pueden solicitar a través de una API REST o consumir como un servicio gRPC.\n",
    "- Este patrón puede ser utilizado para varios flujos de trabajo de ML, tales como **Forecast**, **Web Service**, y **Online Learning**.\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/model-as-a-service.png\" width=\"880\" height=\"50\">\n",
    "\n",
    "#### 2. Model-as-Dependency\n",
    "- **Model-as-Dependency** es probablemente la forma más sencilla de empaquetar un modelo de ML.\n",
    "- Un modelo de ML empaquetado se considera una dependencia dentro de la aplicación de software.\n",
    "- Por ejemplo, la aplicación consume el modelo de ML como una dependencia convencional invocando el método de predicción y pasando los valores.\n",
    "- El valor de retorno de tal ejecución del método es una predicción realizada por el modelo de ML previamente entrenado.\n",
    "- Este enfoque se utiliza principalmente para implementar el patrón de **Forecast**.\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/model-as-a-dependency.png\" width=\"880\" height=\"50\">\n",
    "\n",
    "#### 3. Precompute Serving Pattern\n",
    "- Este tipo de servicio de modelo de ML está estrechamente relacionado con el flujo de trabajo **Forecast**.\n",
    "- Con el patrón de servicio **Precompute**, utilizamos un modelo de ML ya entrenado y pre-computamos las predicciones para el batch de datos entrante.\n",
    "- Las predicciones resultantes se persisten en una base de datos. Por lo tanto, para cualquier solicitud de entrada, consultamos la base de datos para obtener el resultado de la predicción.\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/precompute.png\" width=\"880\" height=\"50\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ded87e4089323",
   "metadata": {},
   "source": [
    "### 1.3.2 🌐 Estrategias de Despliegue de Modelos de Machine Learning\n",
    "En lo siguiente, discutiremos formas comunes de contener modelos entrenados como servicios desplegables, es decir, implementar modelos de ML como contenedores Docker en instancias de la nube y como funciones serverless.\n",
    "\n",
    "#### 1. Implementación de Modelos de ML como Contenedores Docker\n",
    "- Actualmente, no existe una solución estándar y abierta para la implementación de modelos de ML.\n",
    "- Dado que la inferencia de modelos de ML se considera `sin estado`, `ligera` e `idempotente`, la **contenedorización** se convierte en el estándar de facto para la entrega.\n",
    "- Esto significa que implementamos un `contenedor` que envuelve el código de inferencia del modelo de ML.\n",
    "- Para implementaciones en las on-premise, en la nube o híbridas, `Docker` es considerado la tecnología de contenedorización estándar.\n",
    "- Una forma común es empaquetar todo el stack tecnológico de ML (dependencias/paquetes) y el código para la predicción del modelo de ML en un contenedor `Docker`. Luego, `Kubernetes` o una alternativa (como `AWS Fargate`) se encargan de la orquestación.\n",
    "- La funcionalidad del modelo de ML, como la predicción, está disponible a través de una API REST\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/deploy-docker.png\" width=\"880\" height=\"50\">\n",
    "\n",
    "#### 2. Implementación de Modelos de ML como Funciones Serverless\n",
    "- Varios proveedores de la nube ya ofrecen plataformas de machine learning, donde puedes implementar tu modelo utilizando sus servicios.\n",
    "- Ejemplos incluyen **Amazon AWS Sagemaker**, **Google Cloud AI Platform**, **Azure Machine Learning Studio** e **IBM Watson Machine Learning**, entre otros.\n",
    "- Los servicios comerciales en la nube también proporcionan contenedorización de modelos de ML, como **AWS Lambda** y **Google App Engine**.\n",
    "- Para implementar un modelo de ML como una función serverless, el código de la aplicación y las dependencias se empaquetan en archivos .zip, con una función de punto de entrada única.\n",
    "- Esta función puede ser gestionada por principales proveedores de la nube como **Azure Functions**, **AWS Lambda** o **Google Cloud Functions**. Sin embargo, se debe prestar atención a las posibles limitaciones de los artefactos desplegados, como el tamaño del artefacto.\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/deploy-serverless.png\" width=\"880\" height=\"50\">\n",
    "\n",
    "---\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusión 📝\n",
    "\n",
    "A lo largo de este cuaderno exploramos cómo un proyecto de machine learning evoluciona hacia un **sistema de software completo**.\n",
    "- En la **capa de datos**, la preparación, limpieza y validación son tan críticas como el algoritmo.\n",
    "- En la **capa de modelos**, no basta con entrenar: necesitamos evaluar, empaquetar y registrar versiones.\n",
    "- En la **capa de código**, la integración ocurre mediante patrones de *serving*, APIs, contenedores y funciones serverless.\n",
    "\n",
    "Este marco nos permite ver que **la complejidad de ML en producción no está en el algoritmo en sí, sino en todo lo que lo rodea**.\n",
    "\n",
    "👉 Con esta visión, queda claro por qué MLOps es indispensable:\n",
    "asegura que los sistemas de ML sean **reproducibles, escalables y confiables**. "
   ],
   "id": "3b8bc27df39cb08a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
